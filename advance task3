import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
data=pd.read_csv("/content/data.csv")
data.head()
data.shape
type(data)
data.tail()
data["sentiment"].value_counts()
#positive ->1
#negative->0 1
data.replace({"sentiment":{"positive":1,"negative":0}},inplace=True)
data.head()
data.tail()
data["sentiment"].value_counts()
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
train_data,test_data=train_test_split(data,test_size=0.2,random_state=42)
train_data.shape
test_data.shape
tokenizer=Tokenizer(num_words =5000)
test=tokenizer.fit_on_texts(train_data["review"])
x_train=pad_sequences(tokenizer.texts_to_sequences(train_data["review"]),maxlen=200)
x_test=pad_sequences(tokenizer.texts_to_sequences(test_data["review"]),maxlen=200)
x_test
x_train
y_train=train_data["sentiment"]
y_test=test_data["sentiment"]
y_train
y_test
model=Sequential()
model.add(Embedding(input_dim=5000,output_dim=128,input_length=200))
model.add(LSTM(128,dropout=0.2,recurrent_dropout=0.2))
model.add(Dense(1,activation="sigmoid"))
model.summary()

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


# Train the model
history = model.fit(
    x_train,
    y_train,
    epochs=10,
    batch_size=32,
    validation_data=(x_test, y_test),
    verbose=1
)


# Evaluate the model on the test data
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=1)
print(f"Test Accuracy: {test_accuracy}")

# Plot training and validation accuracy and loss
plt.figure(figsize=(12, 6))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy over Epochs')
plt.legend()
# Plot loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss over Epochs')
plt.legend()

plt.show()
